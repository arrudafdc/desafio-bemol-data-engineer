{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a073231",
   "metadata": {},
   "source": [
    "### Setup e Variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2136692",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.bemol_lakehouse import BemolLakeHouse\n",
    "from core.bemol_controller import BemolController\n",
    "from core.bemol_logger import BemolLogger\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d674ce30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciando classe de logger\n",
    "logger = BemolLogger(\"silver_products_sales\")\n",
    "\n",
    "# Configurando Spark com Delta Lake\n",
    "spark = (\n",
    "  SparkSession.builder\n",
    "  .appName(\"TransformacaoSilverProdutos\")\n",
    "  .config(\"spark.jars.packages\", \"io.delta:delta-core_2.12:2.4.0\")\n",
    "  .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\n",
    "  .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "  .getOrCreate()\n",
    ")\n",
    "\n",
    "# Intanciando classe de leitura/escrita de dados\n",
    "lakehouse = BemolLakeHouse(spark, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "544014bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo paths de origem e destino\n",
    "origin_path_carts = \"../data/bronze/carts/\"\n",
    "origin_path_products = \"../data/bronze/products/\"\n",
    "destination_path = \"../data/silver/products_sales/\"\n",
    "\n",
    "# Path para salvar os dados de monitoramento\n",
    "destination_path_monitor = \"../data/monitoring/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b0ea55",
   "metadata": {},
   "source": [
    "### Leitura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f5dd006",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-16 21:13:07,378 - INFO - Iniciando operação: read_bronze\n",
      "2025-10-16 21:13:07,383 - INFO - Lendo dados da camada Bronze: ../data/bronze/carts/\n",
      "25/10/16 21:13:12 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "2025-10-16 21:13:16,357 - INFO - Dados lidos com sucesso da camada Bronze: 14 linhas, 6 colunas.\n",
      "2025-10-16 21:13:16,358 - INFO - Operação read_bronze finalizada em 8.98 segundos.\n",
      "2025-10-16 21:13:16,360 - INFO - Iniciando operação: read_bronze\n",
      "2025-10-16 21:13:16,361 - INFO - Lendo dados da camada Bronze: ../data/bronze/products/\n",
      "2025-10-16 21:13:17,896 - INFO - Dados lidos com sucesso da camada Bronze: 20 linhas, 9 colunas.\n",
      "2025-10-16 21:13:17,897 - INFO - Operação read_bronze finalizada em 1.54 segundos.\n"
     ]
    }
   ],
   "source": [
    "# Lendo dados da camada bronze usando a classe BemolLakeHouse\n",
    "df_carts = lakehouse.read_bronze(origin_path_carts)\n",
    "df_products = lakehouse.read_bronze(origin_path_products)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1346d3a8",
   "metadata": {},
   "source": [
    "### Tranformações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8acfea7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicatas\n",
    "df_products = df_products.dropDuplicates([\"id\"])\n",
    "\n",
    "# Agrega a quantidade total vendida por produto\n",
    "df_sales = df_carts.groupBy(\"product_id\").agg(\n",
    "    sum(\"product_quantity\").alias(\"total_quantity_sold\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec4161a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 21:>                                                         (0 + 7) / 7]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+\n",
      "|product_id|total_quantity_sold|\n",
      "+----------+-------------------+\n",
      "|7         |1                  |\n",
      "|8         |1                  |\n",
      "|5         |2                  |\n",
      "|1         |20                 |\n",
      "|2         |5                  |\n",
      "+----------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_sales.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "07ce8226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enriquecer o dataframe de produtos com a quantidade total vendida\n",
    "df_products_silver = df_products.join(df_sales, df_products.id == df_sales.product_id, \"left\").drop(df_sales.product_id)\n",
    "\n",
    "# Seleciona as colunas relevantes\n",
    "df_products_silver = df_products_silver.select(\"id\", \"product_title\", \"category\", \"rating_count\", \"rating\", \"price\", \"total_quantity_sold\")\n",
    "\n",
    "# Substitui valores nulos na coluna total_quantity_sold por 0\n",
    "df_products_silver = df_products_silver.fillna(0, subset=[\"total_quantity_sold\"])\n",
    "\n",
    "# Calcula a receita total por produto\n",
    "df_products_silver = df_products_silver.withColumn(\"total_revenue\", col(\"price\") * col(\"total_quantity_sold\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "de8122e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------+------------+------+------+-------------------+-------------+\n",
      "| id|       product_title|      category|rating_count|rating| price|total_quantity_sold|total_revenue|\n",
      "+---+--------------------+--------------+------------+------+------+-------------------+-------------+\n",
      "|  1|Fjallraven - Fold...|men's clothing|         120|   3.9|109.95|                 20|       2199.0|\n",
      "|  2|Mens Casual Premi...|men's clothing|         259|   4.1|  22.3|                  5|        111.5|\n",
      "|  3|  Mens Cotton Jacket|men's clothing|         500|   4.7| 55.99|                  6|       335.94|\n",
      "|  4|Mens Casual Slim Fit|men's clothing|         430|   2.1| 15.99|                  0|          0.0|\n",
      "|  5|John Hardy Women'...|      jewelery|         400|   4.6| 695.0|                  2|       1390.0|\n",
      "+---+--------------------+--------------+------------+------+------+-------------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_products_silver.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb284f50",
   "metadata": {},
   "source": [
    "### Escrita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eaa1ae16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adiciona coluna de timestamp de ingestão\n",
    "df_products_silver = BemolController.control_field(df_products_silver, \"silver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ab777c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------+------------+------+------+-------------------+-------------+--------------------+\n",
      "| id|       product_title|      category|rating_count|rating| price|total_quantity_sold|total_revenue|    insertion_silver|\n",
      "+---+--------------------+--------------+------------+------+------+-------------------+-------------+--------------------+\n",
      "|  1|Fjallraven - Fold...|men's clothing|         120|   3.9|109.95|                 20|       2199.0|2025-10-16 21:25:...|\n",
      "|  2|Mens Casual Premi...|men's clothing|         259|   4.1|  22.3|                  5|        111.5|2025-10-16 21:25:...|\n",
      "|  3|  Mens Cotton Jacket|men's clothing|         500|   4.7| 55.99|                  6|       335.94|2025-10-16 21:25:...|\n",
      "|  4|Mens Casual Slim Fit|men's clothing|         430|   2.1| 15.99|                  0|          0.0|2025-10-16 21:25:...|\n",
      "|  5|John Hardy Women'...|      jewelery|         400|   4.6| 695.0|                  2|       1390.0|2025-10-16 21:25:...|\n",
      "+---+--------------------+--------------+------------+------+------+-------------------+-------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_products_silver.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "46c33271",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-16 21:25:21,246 - INFO - Iniciando operação: write_silver\n",
      "2025-10-16 21:25:21,273 - INFO - Escrevendo dados na camada silver em ../data/silver/products_sales/\n",
      "2025-10-16 21:25:24,067 - INFO - Dados escritos com sucesso na camada silver.\n",
      "2025-10-16 21:25:24,382 - INFO - Métricas silver_products_sales: 20 linhas, 9 colunas.\n",
      "2025-10-16 21:25:24,384 - INFO - Operação write_silver finalizada em 3.14 segundos.\n"
     ]
    }
   ],
   "source": [
    "# Escreve os dados na camada silver no formato Delta Lake e no modo overwrite como padrão\n",
    "lakehouse.write_silver(df_products_silver, destination_path, table_name=\"silver_products_sales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1b235f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-16 21:25:52,254 - INFO - Métricas exportadas com sucesso para ../data/monitoring/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[table_name: string, row_count: bigint, col_count: bigint, timestamp: string]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Escreve os dados de monitoramento no formato Delta Lake e no modo overwrite como padrão\n",
    "lakehouse.monitor.export_delta(spark, destination_path_monitor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ce96547c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+---------+---------+-------------------+\n",
      "|table_name           |row_count|col_count|timestamp          |\n",
      "+---------------------+---------+---------+-------------------+\n",
      "|silver_products_sales|20       |9        |2025-10-16 21:25:24|\n",
      "|bronze_products      |20       |9        |2025-10-16 20:27:04|\n",
      "|bronze_carts         |14       |6        |2025-10-16 20:27:10|\n",
      "|silver_users         |10       |8        |2025-10-16 21:10:37|\n",
      "|bronze_users         |10       |13       |2025-10-16 19:46:39|\n",
      "+---------------------+---------+---------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_monitor = spark.read.format(\"delta\").load(destination_path_monitor)\n",
    "df_monitor.show(5, truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
